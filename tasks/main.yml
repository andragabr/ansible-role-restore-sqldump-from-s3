---
# tasks file for restore-sqldump-from-s3

- include: s3cmd.yml
  tags: s3download  

- name: Copy across GPG secret key
  copy: content="{{gpg_secret_key}}" dest=~/sec-gpg.asc

- name: Import GPG secret key into keyring
  command: gpg --allow-secret-key-import --import ~/sec-gpg.asc 
  # Ensure our command is idempotent, e.g. don't fail or show as changed when the key is already in the secret keyring
  register: gpg_result
  failed_when: "'Invalid keyring' in gpg_result.stderr"
  changed_when: "'secret keys imported' in gpg_result.stderr"

- name: Make folder to store backups
  file: path=~/sql-dumps state=directory

# If s3_backup_url_parent is set, then use the most recent backup folder inside

- debug: var=s3_backup_url_parent
  tags: s3download

- name: Determine latest S3 backups folder inside parent folder
  shell: s3cmd ls {{s3_backup_url_parent.rstrip("/")}}/ | tail -1 | awk '{print $2}'
  register: s3_backup_url_parent_result
  changed_when: false
  when: s3_backup_url_parent is defined
  tags: s3download  

- set_fact: s3_backup_url="{{s3_backup_url_parent_result.stdout}}"
  when: s3_backup_url_parent is defined
  tags: s3download

# Strip trailing slash from s3_backup_url (if necessary) since we will set them explicitly when needed later
- set_fact: s3_backup_url="{{s3_backup_url.rstrip("/")}}"
  tags: s3download

- debug: var=s3_backup_url
  tags: s3download

- debug: var=s3_databases
  tags: s3download
  when: s3_databases is defined  

# If s3_databases is not defined try to download them all

- name: Determine last file in S3 backups folder
  shell: s3cmd ls {{s3_backup_url}}/ | tail -1 | grep -o '[^/]*sql.gz.gpg$'
  register: s3_last_file
  changed_when: false
  when: s3_databases is not defined
  tags: s3download  

- debug: var=s3_last_file
  when: s3_databases is not defined
  tags: s3download

- name: Download all S3 database backups
  command: s3cmd --skip-existing --recursive get {{s3_backup_url}}/ ~/sql-dumps/
  args:
    creates: ~/sql-dumps/{{ s3_last_file.stdout }}
  register: s3cmd
  when: s3_databases is not defined
  tags: s3download

# If s3_databases is defined and some databases are specified, download them one by one

- name: Download individual S3 database backups
  command: s3cmd get {{s3_backup_url}}/{{item}}.sql.gz.gpg ~/sql-dumps/{{item}}.sql.gz.gpg
  args:
    creates: ~/sql-dumps/{{item}}.sql.gz.gpg
  register: s3cmd
  with_items: s3_databases
  when: s3_databases is defined
  tags: s3download

- debug: var=s3cmd.stdout_lines
  tags: s3download  

- name: Enumerate databases from backup files
  shell: find ~/sql-dumps -maxdepth 1 ! -name 'mysql.sql.gz.gpg' -name '*.sql.gz.gpg' -printf "%f\n" | sed s/.sql.gz.gpg$//
  register: database_list
  changed_when: False
  tags: dbimport    
 
- name: Create databases in MySQL
  mysql_db: name={{ item }} state=present
  with_items: "{{database_list.stdout_lines}}"
  tags: dbimport

- name: Decrypt and decompress SQL dumps (also truncate original encrypted files)
  shell: "(gpg --decrypt ~/sql-dumps/{{ item }}.sql.gz.gpg | gunzip > ~/sql-dumps/{{ item }}.sql) && : > ~/sql-dumps/{{ item }}.sql.gz.gpg"
  args:
    creates: ~/sql-dumps/{{ item }}.sql
  with_items: "{{database_list.stdout_lines}}"
  tags: dbimport

# NB: Ansible 1.9.4 uses \\\\1 whereas Ansible 2+ uses \\1 
- name: Remove inserts from tables we wish to exclude (Ansible 2+ backslash escaping)
  shell: "cat ~/sql-dumps/{{ item.keys() | first }}.sql | {{ item[item.keys() | first] | map(\"regex_replace\", \"^(.*)$\", \"sed '/INSERT INTO `\\1`/d'\") | join(\" 
| \") }} > ~/sql-dumps/{{ item.keys() | first }}.sql.tmp && mv ~/sql-dumps/{{ item.keys() | first }}.sql.tmp ~/sql-dumps/{{ item.keys() | first }}.sql"
  with_items: exclude_inserts
  when: exclude_inserts is defined and ansible_version.major|int >= 2
  tags: dbimport
  
- name: Remove inserts from tables we wish to exclude (Ansible 1 backslash escaping)
  shell: "cat ~/sql-dumps/{{ item.keys() | first }}.sql | {{ item[item.keys() | first] | map(\"regex_replace\", \"^(.*)$\", \"sed '/INSERT INTO `\\\\1`/d'\") | join(\"
| \") }} > ~/sql-dumps/{{ item.keys() | first }}.sql.tmp && mv ~/sql-dumps/{{ item.keys() | first }}.sql.tmp ~/sql-dumps/{{ item.keys() | first }}.sql"
  with_items: exclude_inserts
  when: exclude_inserts is defined and ansible_version.major|int == 1 
  tags: dbimport

- name: Check which SQL dumps have already had their row format set
  stat: path=~/sql-dumps/{{ item }}.row-format-set
  register: database_list_row_format_status
  with_items: "{{database_list.stdout_lines}}"
  tags: dbimport

- name: Set ROW_FORMAT if it is not previously defined to CREATE TABLE statements in SQL dumps
  shell: perl -i -pe '/ROW_FORMAT=/ or s/ENGINE=InnoDB/ENGINE=InnoDB ROW_FORMAT={{ innodb_row_format }}/' ~/sql-dumps/{{ item.0 }}.sql && touch ~/sql-dumps/{{ item.0 }}.row-format-set
  with_together:
    - "{{database_list.stdout_lines}}"
    - "{{database_list_row_format_status.results|map(attribute='stat.exists')|map('default','')|list}}"
  when: >
    (innodb_row_format is defined)
    and (not item.1)
  tags: dbimport 

- name: Check which databases have already been imported
  stat: path=~/sql-dumps/{{ item }}.imported
  register: database_list_import_status
  with_items: "{{database_list.stdout_lines}}"
  tags: dbimport

- name: Import SQL dumps into MySQL (and truncate original files)
  shell: "mysql -D {{ item.0 }} < ~/sql-dumps/{{ item.0 }}.sql && touch ~/sql-dumps/{{ item.0 }}.imported && : > ~/sql-dumps/{{ item.0 }}.sql"
  with_together:
    - "{{database_list.stdout_lines}}"
    - "{{database_list_import_status.results|map(attribute='stat.exists')|map('default','')|list}}"
  when: not item.1
  tags: dbimport
